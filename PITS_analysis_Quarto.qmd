---
title: "PITS_quarto"
format: html
editor: visual
---
last updated 3/19/2025

## Running Code

### load libraries
```{r}
# load libraries 
library(plotly)
library(tidyverse)
library(readr)
library(crosstalk)
library(lubridate)
```

## Read in PITS data

```{r}
# read in data
PITS_ListIncidents_2023 <- read_csv("~/data librarian/PITS_Data/PITS_ListIncidents_2023.csv")
PITS_ListIncidents_2023$`Incident ID` <- as.character(PITS_ListIncidents_2023$`Incident ID`)
PITS_ListIncidents_2023$Time <- as.character(PITS_ListIncidents_2023$Time)

PITS_ListIncidents_2024 <- read_csv("~/data librarian/PITS_Data/PITS_ListIncidents_2024.csv")

PITS_ListIncidents_2024 <- PITS_ListIncidents_2024[,-(21:25)] 

PITS_ListIncidents_2025 <- read_csv("~/data librarian/PITS_Data/PITS_ListIncidents_Jan2025-March19_2025.csv")

# merge the years
PITS_2023_2025 <- rbind(PITS_ListIncidents_2023, PITS_ListIncidents_2024, PITS_ListIncidents_2025)

```

### Count unique reporters

```{r}
PITS_2023_2025 %>% summarise(count = n_distinct(Reporter))

# as.list(unique(PITS_2023_2024$Reporter))

```

## Mask Reporter IDs

```{r}
# Generate unique alternate IDs
# Function to generate consistent masked IDs
generate_consistent_ids <- function(names) {
  # Create a unique mapping of original names to masked IDs
  unique_names <- unique(names)
  masked_ids <- paste0("ID_", sprintf("%04d", seq_along(unique_names)))
  
  # Create a named vector for easy lookup
  id_mapping <- setNames(masked_ids, unique_names)
  
  # Map the original names to their consistent masked IDs
  return(id_mapping[names])
}

# Generate consistent masked IDs
PITS_2023_2025$masked_reporter <- generate_consistent_ids(PITS_2023_2025$Reporter)

# Create a lookup table
lookup_table_reporter <- PITS_2023_2025 %>%
  select(original_name = Reporter, masked_reporter) %>%
  distinct()

```

```{r}
# Turn follow-up into a binary 
# none versus other text
PITS_2023_2025 <- PITS_2023_2025 %>% 
  mutate(Followup_binary = ifelse(Followup == "NONE", 0, 1))

```

```{r}
# save a copy of the data without discerning columns
PITS_2023_2025_public <- 
  PITS_2023_2025 %>%
  select(-Reporter, -People, -Followup, -Description)

```

## Add datetime PITS data

```{r}
#| echo: false
# change date 
PITS_2023_2025_public$Date2 <- as.Date(PITS_2023_2025_public$Date, format = "%m/%d/%Y")


```

The `echo: false` option disables the printing of code (only output is displayed).

# Clean up the Time format in PITS

```{r}
# Using rowwise() to parse time

# remove NA times
# PITS_2023_2025_public <- PITS_2023_2025_public %>% 
#   filter(!is.na(Time))

PITS_2023_2025_public <- PITS_2023_2025_public %>%
  rowwise() %>%
  mutate(
    # Process one row at a time
    time_parsed = {
      time_str <- Time
      if (is.na(time_str) || !is.character(time_str)) {
        NA
      } else if (grepl("AM|PM", time_str, ignore.case = TRUE)) {
        parse_date_time(time_str, orders = c("I:M p", "H:M p"))
      } else if (grepl(":", time_str, fixed = TRUE)) {
        if (length(gregexpr(":", time_str)[[1]]) == 2) {
          parse_date_time(time_str, orders = "H:M:S")
        } else {
          parse_date_time(time_str, orders = "H:M")
        }
      } else {
        NA
      }
    }
  ) %>%
  ungroup() %>%
  mutate(
    time_24h = format(time_parsed, "%H:%M:%S"),
    time_12h = format(time_parsed, "%I:%M:%S %p")
  )

```

## Standardize Location format

```{r}
# match location standard for computer use
# location name consistency 
# Create a master location mapping table
location_mapping <- data.frame(
  standard_name = c(
    "Joel D. Valdez-Main", "Himmel Park", "Murphy-Wilmot", "Woods Memorial",
    "Valencia", "Martha Cooper", "Flowing Wells", "Sahuarita",
    "Wheeler Taft Abbett", "Miller-Golf Links", "Eckstrom-Columbus",
    "Santa Rosa", "Sam Lena-South Tucson", "Oro Valley", "Quincie Douglas",
    "Bookmobile/Readrunners", "Caviglia-Arivaca", "Dewhirst-Catalina", 
    "Dusenberry-River", "El Rio", "Frank De La Cruz-El Pueblo",
    "Joyner-Green Valley", "Kirk-Bear Canyon", "Nanini", 
    "Richard Elias-Mission", "Salazar-Ajo", "Southwest",
    "W. Anne Gibson-Esmond Station", "Web Renewal"
  ),
  stringsAsFactors = FALSE
)

# Function to standardize location names
standardize_location <- function(location) {
  # Remove common suffixes
  location <- gsub(" Branch Library$|\\s+Library$", "", location)
  
  # Handle specific cases
  location <- gsub("^Joel Valdez Main$", "Joel D. Valdez-Main", location)
  location <- gsub("^Joel D Valdez Main$", "Joel D. Valdez-Main", location)
  location <- gsub("^Bookmobile-Readrunners$", "Bookmobile/Readrunners", location)
  location <- gsub("^Quincie Douglas$", "Quincie Douglas", location)
  location <- gsub("^Virtual Library$", "Web Renewal", location)
  
  # Return the standardized name
  return(location)
}

# Apply standardization to each dataset
standardize_dataset <- function(df, location_col_name) {
  if(location_col_name %in% colnames(df)) {
    df$Location_Standard <- standardize_location(df[[location_col_name]])
    return(df)
  } else {
    warning(paste("Column", location_col_name, "not found in dataset"))
    return(df)
  }
}

# Apply to all three datasets
PITS_2023_2025_public <- standardize_dataset(PITS_2023_2025_public, "Location")
# last52weeks_circ <- standardize_dataset(last52weeks_circ, "Location")
# last52weeks_comp <- standardize_dataset(last52weeks_comp, "Location")

```

# hourly summary of PITS from Jan 2023 to March 2025
```{r}
# group pits incidents by the hour

# Assuming your data is in a data frame called 'df' with a column 'timestamp'
# Group by hour
PITS_2023_2025_public$hour_group <- floor_date(PITS_2023_2025_public$time_parsed, 
                                               unit = "hour")

# For visualization/labeling, you can format the hour
PITS_2023_2025_public$hour_label <- format(PITS_2023_2025_public$hour_group, "%H:00-%H:59")


```

```{r}
# remove NA dates
PITS_2023_2025_public <- PITS_2023_2025_public %>% 
  filter(!is.na(Date))
```

## Read in preprocessed data
```{r}
# # bring in the data
PITS_2023_2025_public <- read_csv("data/pits2023-2025-public.csv")
PITS_2023_2025_public  <- PITS_2023_2025_public [,-1]
```
# Group by hour and count events
```{r}
# # Group by hour and count events
hourly_summary <- PITS_2023_2025_public %>%
  select(hour_label, Location, Infractions, time_parsed, Date2) %>%
  # mutate(hour_group = floor_date(time_parsed, unit = "hour")) %>%
  group_by(hour_label) %>%
  summarize(
    Total_Hourly_Count = n(),
    # other aggregate metrics as needed
  )

hourly_location_date_summary <- PITS_2023_2025_public %>%
  select(hour_label, hour_group, Location_Standard, time_parsed, Date2) %>%
  # Group by date as well as hour and location
  group_by(Date2, hour_label, Location_Standard) %>%
  summarize(
    count = n(),
    .groups = "drop"
  ) %>%
  # Create a wide format with Location combinations as columns
  pivot_wider(
    id_cols = c(Date2, hour_label),  # Keep Date2 as an identifier column
    names_from = Location_Standard,
    values_from = count,
    values_fill = 0
  )

# more information 
hourly_location_summary <- PITS_2023_2025_public %>%
  select(hour_label, hour_group, Location_Standard, time_parsed, Date2) %>% 
  # mutate(hour_group = floor_date(time_parsed, unit = "hour")) %>%
  group_by(hour_label, Location_Standard) %>%
  summarize(
    count = n(),
    .groups = "drop"
  ) %>%
  # Create a wide format with Location combinations as columns
  pivot_wider(
    names_from = c(Location_Standard),
    values_from = count,
    values_fill = 0
  )



# join the two charts
hourly_loc_sum_total <-  hourly_summary %>% 
                                    left_join(hourly_location_date_summary)
```

# Visualize hourly data
```{r}
# Basic interactive bar chart of hourly counts
plot_hourly <- plot_ly(hourly_loc_sum_total,
                       x = ~hour_label,
                       y = ~Total_Hourly_Count,
                       type = "bar",
                       name = "Total") %>%
  layout(title = "Events by Hour",
         xaxis = list(title = "Hour of Day", tickangle = 45),
         yaxis = list(title = "Number of Events"),
         hovermode = "compare")

# For location breakdown, convert to long format first
hourly_loc_long <- hourly_loc_sum_total %>%
  pivot_longer(
    cols = -c(hour_label, Total_Hourly_Count, Date2),
    names_to = "Location",
    values_to = "Count"
  )

# Interactive stacked bar chart by location
plot_by_location <- plot_ly(hourly_loc_long,
                           x = ~hour_label,
                           y = ~Count,
                           color = ~Location,
                           type = "bar") %>%
  layout(title = "Events by Location and Hour",
         xaxis = list(title = "Hour of Day", tickangle = 45),
         yaxis = list(title = "Number of Events"),
         barmode = "stack",
         hovermode = "compare")

# # Display the plots
# plot_hourly

```

# Visualize with location
```{r}
# Create a plotly visualization with buttons to filter by location but no legend
locations <- sort(unique(hourly_loc_long$Location))  # Sort locations alphabetically

# Create a list of buttons, one for each location plus "All"
buttons <- list(
  list(
    method = "update",
    args = list(list(visible = rep(TRUE, length(locations))),
                list(title = "Events by Location and Hour - All Locations")),
    label = "All"
  )
)

# Add a button for each location in alphabetical order
for(i in 1:length(locations)) {
  visible <- rep(FALSE, length(locations))
  visible[i] <- TRUE
  
  buttons <- c(buttons, list(
    list(
      method = "update",
      args = list(list(visible = visible),
                  list(title = paste0("Events by Location and Hour - ", locations[i]))),
      label = locations[i]
    )
  ))
}

# Create the base plot
plot_by_location <- plot_ly()

# Add each location as a separate trace
for(i in 1:length(locations)) {
  loc_data <- filter(hourly_loc_long, Location == locations[i])
  
  plot_by_location <- plot_by_location %>%
    add_trace(
      data = loc_data,
      x = ~hour_label,
      y = ~Count,
      type = "bar",
      name = locations[i],
      marker = list(color = colorRampPalette(c("#1f77b4", "#ff7f0e", "#2ca02c", "#d62728"))(length(locations))[i])
    )
}

# Add the buttons and layout - moved to upper left and removed legend
plot_by_location <- plot_by_location %>%
  layout(
    title = "Events by Location and Hour",
    xaxis = list(title = "Hour of Day", tickangle = 45),
    yaxis = list(title = "Number of Events"),
    barmode = "stack",
    hovermode = "compare",
    showlegend = FALSE,  # Remove the legend
    updatemenus = list(
      list(
        type = "dropdown",
        buttons = buttons,
        direction = "down",
        showactive = TRUE,
        x = 1.1,
        y = 1
    ))
  )

# Display the plot
plot_by_location
```

```{r}
# remove if date is na

hourly_loc_long <- hourly_loc_long %>%
  filter(!is.na(Date2))

```

```{r}
library(usethis) 
usethis::edit_r_environ()
```

## hourly location summary
```{r}
# More efficient approach
hourly_location_summary <- PITS_2023_2025_public %>%
  # Select only necessary columns to reduce memory usage
  select(hour_label, Location_Standard, Date2) %>%
  # Pre-aggregate to reduce data size before pivoting
  count(Date2, hour_label, Location_Standard, name = "count") %>%
  # Now pivot with the smaller dataset
  pivot_wider(
    id_cols = c(Date2, hour_label),
    names_from = Location_Standard,
    values_from = count,
    values_fill = 0
  )
```


# Process by date chunks

```{r}
# Get unique dates
unique_dates <- unique(PITS_2023_2025_public$Date2)
# Process in chunks of 30 days
chunk_size <- 30
date_chunks <- split(unique_dates, ceiling(seq_along(unique_dates)/chunk_size))

# Initialize empty result dataframe
hourly_location_summary <- data.frame()

# Process each chunk
for(chunk in date_chunks) {
  temp_df <- PITS_2023_2025_public %>%
    filter(Date2 %in% chunk) %>%
    select(hour_label, Location_Standard, Date2) %>%
    count(Date2, hour_label, Location_Standard, name = "count") %>%
    pivot_wider(
      id_cols = c(Date2, hour_label),
      names_from = Location_Standard,
      values_from = count,
      values_fill = 0
    )
  
  # Append to result
  hourly_location_summary <- bind_rows(hourly_location_summary, temp_df)
}

```

## adding a data slider to the graph
```{r}
# getting tge date tune slider but this only produced a date drop down
# Get unique dates and locations
dates <- sort(unique(hourly_loc_long$Date2))
locations <- sort(unique(hourly_loc_long$Location))

# Create a base plot
p <- plot_ly()

# Add traces for each location
for (loc in locations) {
  loc_data <- filter(hourly_loc_long, Location == loc)
  p <- p %>% add_trace(
    data = loc_data,
    x = ~hour_label,
    y = ~Count,
    type = "bar",
    name = loc,
    transforms = list(
      list(
        type = 'filter',
        target = ~Location,
        operation = '=',
        value = loc
      ),
      list(
        type = 'filter',
        target = ~Date2,
        operation = 'in',
        value = dates[1]  # Default to first date
      )
    )
  )
}

# Create location filter buttons
loc_buttons <- lapply(c("All", locations), function(loc) {
  if (loc == "All") {
    list(
      method = "update",
      args = list(
        list(visible = rep(TRUE, length(locations))),
        list(title = "Events by Location and Hour - All Locations")
      ),
      label = "All Locations"
    )
  } else {
    visible <- rep(FALSE, length(locations))
    visible[match(loc, locations)] <- TRUE
    list(
      method = "update",
      args = list(
        list(visible = visible),
        list(title = paste0("Events by Location and Hour - ", loc))
      ),
      label = loc
    )
  }
})

# Create date filter buttons (showing only first 10 dates if there are many)
date_buttons <- lapply(dates[1:min(10, length(dates))], function(date) {
  list(
    method = "restyle",
    args = list(
      "transforms[1].value", date
    ),
    label = as.character(date)
  )
})

# Add buttons and layout
p <- p %>%
  layout(
    title = "Events by Location and Hour",
    xaxis = list(title = "Hour of Day", tickangle = 45),
    yaxis = list(title = "Number of Events"),
    barmode = "stack",
    hovermode = "compare",
    showlegend = TRUE,
    updatemenus = list(
      # Location filter
      list(
        type = "dropdown",
        active = 0,
        buttons = loc_buttons,
        direction = "down",
        showactive = TRUE,
        x = 0.1,
        y = 1.1,
        name = "Location Filter"
      ),
      # Date filter 
      list(
        type = "dropdown",
        active = 0,
        buttons = date_buttons,
        direction = "down",
        showactive = TRUE,
        x = 0.4,
        y = 1.1,
        name = "Date Filter"
      )
    )
  )
# 
# p
```

# Crosstalk Plotly Graph by location and hour
```{r}
library(plotly)
library(dplyr)
library(crosstalk)

# Convert hourly_location_summary to long format if needed
hourly_loc_long <- hourly_location_summary %>%
  pivot_longer(
    cols = -c(Date2, hour_label),
    names_to = "Location",
    values_to = "Count"
  )

# Make sure Date2 is a proper Date object
hourly_loc_long$Date2 <- as.Date(hourly_loc_long$Date2)

hourly_loc_long2 <- hourly_loc_long %>%
  filter(!is.na(hour_label))

# Create a shared data object
sd <- SharedData$new(hourly_loc_long2)

# Create the plotly visualization
p <- plot_ly(sd, x = ~hour_label, y = ~Count, color = ~Location, type = "bar",  text = ~paste("Hour: ", hour_label,
                          "<br>Location: ", Location,
                          "<br>Count: ", Count,
                          "<br>Date: ", Date2),
             hoverinfo = "text") %>% 
  layout(
    title = "Events by Location and Hour",
    xaxis = list(title = "Hour of Day", tickangle = 45),
    yaxis = list(title = "Number of Events"),
    barmode = "stack",
    hovermode = "compare",
    showlegend = FALSE
  )
# Create filter panel
filter_panel <- list(
  filter_slider("Date2", "Date Range", sd, ~Date2, width = "100%"),
  filter_select("Location", "Location", sd, ~Location, multiple = TRUE)
)


```

## JavaScript to help produce a prettier image
```{js, echo=FALSE}

var fitTheScreen = window.setInterval(function(){
  if ( $(".irs-from").text() === $(".irs-min").text() ) {
    $(".irs-from").css({"left": "10%"});
  }

  if ( $(".irs-to").text() === $(".irs-max").text() ) {
    $(".irs-to").css({"left": "86%"});
  }

}, 1000);

```

```{r}
# Combine filters with plot
bscols(
  widths = c(3, 9),
  filter_panel,
  p
)
```

```{r}

# PITS_categories <- PITS_2023_2025_public %>%
#   # Create row ID for later joining
#   mutate(row_id = row_number()) %>%
#   # Create a new column that takes values from Infractions when Infraction Categories is problematic
#   mutate(category_source = case_when(
#     is.na(`Infraction Categories`) | `Infraction Categories` == "null" |
#     str_detect(`Infraction Categories`, "#") ~ `Infractions`,
#     TRUE ~ `Infraction Categories`
#   ))
```

# less aggressive parsing that works better
```{r}
# 
PITS_categories <- PITS_2023_2025_public %>%
  # Create row ID for later joining
  mutate(row_id = row_number()) %>%
  # Process the categories column as before
  mutate(categories = str_replace_all(`Infraction Categories`, "[,~]", ",")) %>%
  # Split by comma
  # separate_rows(categories, sep = ",") %>%
  # Clean up each value
  # mutate(categories = str_trim(`Infraction Categories`)) %>%
  mutate(categories = str_replace_all(categories, "[~,]", ",")) %>%
  mutate(categories = str_replace_all(categories, "^\\s*\\d+(\\.\\d+)*\\s+", "|")) %>%

  mutate(categories = case_when(
    categories == "null" ~ "Other",
    categories == "null,null" ~ "Other",
    categories == "null~null" ~ "Other",
    categories == "" ~ "Other",
    str_detect(categories, "^#+$") ~ "Other",
    TRUE ~ categories
  )) %>%
  # Replace "or Illegal Conduct" with "Illegal Conduct"
  # mutate(categories = ifelse(categories == "or Illegal Conduct", "Illegal Conduct", categories)) %>%
  # Remove "or" and "and" if they appear as standalone words
  # mutate(categories = str_replace(categories, "^(or|and)$", "")) %>%
  # Remove empty strings, null values, and categories with hash symbols
  filter(categories != "") %>%
  filter(categories != "null") %>%
  filter(!str_detect(categories, "#"))

```


## attempt to parse categories with comma separator
```{r}
# Function to properly parse categories with comma handling
parse_categories <- function(categories_string) {
  if (is.na(categories_string) || categories_string == "") {
    return(character(0))
  }
  
  # Replace commas followed by spaces with a temporary delimiter
  # This preserves phrases like "Dangerous, Threatening, or Illegal Conduct"
  temp_string <- gsub(", ", "<<COMMA_SPACE>>", categories_string)
  
  # Split by remaining commas (those without spaces after them)
  split_categories <- strsplit(temp_string, ",")[[1]]
  
  # Restore the original comma-space combinations
  result <- gsub("<<COMMA_SPACE>>", ", ", split_categories)
  
  # Trim any whitespace
  result <- trimws(result)
  
  return(result)
}

# Example usage
example_categories <- c(
  "Dangerous, Threatening, or Illegal Conduct,Disruptive Personal Behavior,Use and preservation of library materials and property",
  "Children in the Library,Incident Impact Level - Staff Traumatic Stress",
  "Dangerous, Threatening, or Illegal Conduct,Disruptive,Personal Behavior",
  NA,
  ""
)

# Apply the function to each example
results <- lapply(example_categories, parse_categories)

# Display the results
for (i in seq_along(example_categories)) {
  if (!is.na(example_categories[i]) && example_categories[i] != "") {
    cat("Original:", example_categories[i], "\n")
    cat("Parsed:", paste(results[[i]], collapse = " | "), "\n\n")
  } else {
    cat("Original:", example_categories[i], "(empty or NA)\n")
    cat("Parsed:", length(results[[i]]), "items\n\n")
  }
}

# To use with a dataframe:
PITS_categories2 <- PITS_categories %>%
  mutate(parsed_categories = lapply(categories, parse_categories)) %>%
  unnest(parsed_categories)
```


```{r}
# pits summary
PITS_summary <- PITS_categories2 %>%
  group_by(parsed_categories) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(parsed_categories, desc(count))

print(PITS_summary)
```

# parse empty categories
```{r}
# Filter for rows where Infraction Categories is empty, null, or contains #
PITS_empty_categories <- PITS_2023_2025_public %>% 
  filter(`Infraction Categories` == "" | 
         `Infraction Categories` == "null" | 
         str_detect(`Infraction Categories`, "#") |
         is.na(`Infraction Categories`))

PITS_empty_categories <- PITS_empty_categories %>%
  # Create row ID for later joining
  mutate(row_id = row_number()) %>%
  # Create a new column that takes values from Infractions when Infraction Categories is problematic
  mutate(category_source = case_when(
    is.na(`Infraction Categories`) | `Infraction Categories` == "null" |
    str_detect(`Infraction Categories`, "#") ~ `Infractions`,
    TRUE ~ `Infraction Categories`
  )) %>%
  mutate(category_source = str_replace_all(category_source, "^\\s*\\d+(\\.\\d+)*\\s+", "|")) %>%
   mutate(category_source = iconv(category_source, "UTF-8", "ASCII", sub="")) %>%
  # Simply rename null and hash values to "Other" in the category_source column
  mutate(category_source = case_when(
    category_source == "null" ~ "Other",
    category_source == "null~null" ~ "Other",
    str_detect(category_source, "^#+$") ~ "Other",
    TRUE ~ category_source
  ))

```

# long version of parsing empty
```{r}
# # Filter for rows where Infraction Categories is empty, null, or contains #
# PITS_empty_categories <- PITS_2023_2025_public %>%
#   filter(`Infraction Categories` == "" |
#          `Infraction Categories` == "null" |
#          str_detect(`Infraction Categories`, "#") |
#          is.na(`Infraction Categories`))

# #
# PITS_empty_categories <- PITS_empty_categories %>%
#   # Create row ID for later joining
#   mutate(row_id = row_number()) %>%
#   # Create a new column that takes values from Infractions when Infraction Categories is problematic
# #   mutate(category_source = case_when(
# #     is.na(`Infraction Categories`) | `Infraction Categories` == "null" |
# #     str_detect(`Infraction Categories`, "#") ~ `Infractions`,
# #     TRUE ~ `Infraction Categories`
# #   )) %>%
#   mutate(categories = str_replace_all(category_source, "[,]", ",")) %>%
#   # # Replace null values and hash-only strings with "Other"
#   mutate(categories = case_when(
#     categories == "null" ~ "Other",
#     categories == "" ~ "Other",
#     str_detect(categories, "^#+$") ~ "Other",
#     TRUE ~ categories
#   )) %>%
#   # Remove numeric identifiers (like 1.1.7.3)
#   # # Process the categories column
#   mutate(categories = str_replace_all(categories, "^\\s*\\d+(\\.\\d+)*\\s+", "|")) %>%
# #   # # Split by comma and tilde
#   separate_rows(categories, sep = "[,~]") %>%
# #   # Clean up each value
#   mutate(categories = str_trim(categories))
#   # Filter out any remaining empty values after processing
#   # filter(categories != "")
# 
# # To join this back to the original dataframe
# # Create a lookup table with the processed categories
# category_lookup <- PITS_empty_categories %>%
#   select(row_id, categories) %>%
#   group_by(row_id) %>%
#   summarize(clean_categories = paste(categories, collapse = ", "))
# 


```


```{r}
# Clean the categories column by removing number patterns and creating separations
# PITS_empty_categories <- PITS_empty_categories %>%
#   # Create a new cleaned_categories column
#   mutate(cleaned_categories = sapply(categories, function(text) {
#     if (is.na(text) || text == "") {
#       return(NA)
#     }
#     
#     # Replace tildes with multiple spaces
#     text <- gsub("~", "    ", text)
#     
#     # Split by 3 or more spaces
#     parts <- unlist(strsplit(text, "\\s{3,}"))
#     parts <- trimws(parts)
#     
#     # Remove numbering patterns (like 2.1 or 1.1.7.2)
#     parts <- gsub("\\d+(\\.\\d+)*\\s+", "", parts)
#     
#     # Remove any empty parts
#     parts <- parts[parts != ""]
#     
#     # Join with a separator that works well for pivot_wider
#     return(paste(parts, collapse = " | "))
#   }))
# 
# # Now create a long format dataframe suitable for pivot_wider
# PITS_empty_categories_long <- PITS_empty_categories %>%
#   # Split the cleaned_categories into separate rows
#   separate_rows(cleaned_categories, sep = " \\| ") %>%
#   # Create a dummy value column for pivot_wider (e.g., count of 1 for each category)
#   mutate(value = 1)
# 
# # Create a wide format with categories as columns
# PITS_empty_categories_wide <- PITS_empty_categories_long %>%
#   pivot_wider(
#     id_cols = c(row_id), # Include any identifier columns you need
#     names_from = cleaned_categories,
#     values_from = value,
#     values_fill = 0 # Fill missing values with 0
#   )
# 
# # Preview the results
# head(PITS_empty_categories_wide)
```


## unique counts of empty category
```{r}
# get the various values in the list
# Count and display unique values in category_source
unique_counts <- PITS_empty_categories %>%
  count(category_source, sort = TRUE) %>%
  rename(count = n)

# Display the results
print(unique_counts)


```


# parsing and pivoting wider for empty categories
```{r}


```


```{r}
# To use with a dataframe:
# PITS_empty_categories2 <- PITS_empty_categories %>%
#   mutate(clean_text_categories = lapply(categories, clean_text)) %>%
#   unnest(clean_text_categories)

# from pits Empty categories create a way to clean up the data
# subset if categories are empty
# this code parses why too much stuff
# 
# PITS_empty_categories <- PITS_2023_2025_public %>% 
#   # Filter for rows where Infraction Categories is empty, null, or contains #
#   filter(`Infraction Categories` == "" | 
#          `Infraction Categories` == "null" | 
#          str_detect(`Infraction Categories`, "#") |
#          is.na(`Infraction Categories`))
# 
# PITS_empty_categories <- PITS_empty_categories %>%
#   # Create row ID for later joining
#   mutate(row_id = row_number()) %>%
#   # Create a new column that takes values from Infractions when Infraction Categories is problematic
#   mutate(category_source = case_when(
#     is.na(`Infraction Categories`) | `Infraction Categories` == "null" |
#     str_detect(`Infraction Categories`, "#") ~ `Infractions`,
#     TRUE ~ `Infraction Categories`
#   )) %>%
#   
#   # Process the categories column
#   mutate(categories = str_replace_all(category_source, "[~,]", ",")) %>%
#   # # For Infractions column values, clean up numeric codes like 1.14
#   mutate(categories = str_replace_all(categories, "\\s*\\d+\\.\\d+\\s*", "")) %>%
#   # Split by comma
#   # separate_rows(categories, sep = ",") %>% 
#   # Clean up each value
#   mutate(categories = str_trim(categories)) %>% 
#   # Replace "or Illegal Conduct" with "Illegal Conduct"
#   # mutate(categories = ifelse(categories == "or Illegal Conduct", "Illegal Conduct", categories)) %>%
#   # # Remove "or" and "and" if they appear as standalone words
#   mutate(categories = str_replace(categories, "^(or|and)$", ""))
#   # Remove empty strings, null values, and categories with hash symbols
#   # filter(categories != "") %>%
#   # filter(categories != "null") %>%
#   # filter(!str_detect(categories, "#"))


```

# function to parse infractions
```{r}
# Function to parse infraction string into clean categories
parse_infractions <- function(infraction_string) {
  # Handle null or hash-only values first
  if (is.null(infraction_string) || is.na(infraction_string) || 
      infraction_string == "null" || grepl("^#+$", infraction_string)) {
    return("Other")
  }
  
  # Step 1: Replace ~ with a special delimiter to handle the major category breaks
  infraction_string <- gsub("~", " ||| ", infraction_string)
  
  # Step 2: Split by number patterns followed by spaces
  # This regular expression matches patterns like "1.1.7.3 " or "2.1 "
  categories <- unlist(strsplit(infraction_string, "\\s+\\d+(\\.\\d+)*\\s+"))
  
  # Step 3: Clean up the categories
  categories <- sapply(categories, function(cat) {
    # Trim whitespace
    cat <- trimws(cat)
    
    # Replace any categories that are "null" or just hash marks with "Other"
    if (cat == "null" || grepl("^#+$", cat)) {
      return("Other")
    }
    
    # Handle the special delimiter we added
    if(grepl(" \\|\\|\\| ", cat)) {
      parts <- unlist(strsplit(cat, " \\|\\|\\| "))
      # Check each part for null or hash marks
      parts <- sapply(parts, function(p) {
        if (trimws(p) == "null" || grepl("^#+$", trimws(p))) {
          return("Other")
        } else {
          return(p)
        }
      })
      return(parts)
    }
    
    return(cat)
  })
  
  # Flatten the list
  categories <- unlist(categories)
  
  # Step 4: Remove any empty categories and trim whitespace again
  categories <- categories[categories != ""]
  categories <- trimws(categories)
  
  # Step 5: Handle any remaining numeric prefixes at the beginning of categories
  categories <- gsub("^\\d+(\\.\\d+)*\\s+", "", categories)
  
  return(categories)
}

# Example usage with various inputs
examples <- list(
  "Dangerous, Threatening, or Illegal Conduct    1.1.7.3 Harassment: Profane, offensive, abusive language    1.1.7.2 Harassment: Conduct, stares, or gestures causing fear of safety, distress, alarm, harassment",
  "null",
  "##############",
  "Disruptive behavior~null~Called 911 for medical"
)

# Parse and display results for each example
for (i in seq_along(examples)) {
  cat("Example", i, ":", "\n")
  print(parse_infractions(examples[[i]]))
  cat("\n")
}

```


```{r}
```


```{r}
# sort out types of PITS
# Extract all unique categories
# library(dplyr)
# library(tidyr)
# library(stringr)
# 
# unique_categories <- PITS_2023_2025_public %>%
#   # First convert all separators to a common one
#   mutate(categories = str_replace_all(`Infraction Categories`, "[,~]", ",")) %>%
#   # Replace " or " and " and " with commas when they appear between words
#   mutate(categories = str_replace_all(categories, "\\s+or\\s+", ",")) %>%
#   mutate(categories = str_replace_all(categories, "\\s+and\\s+", ",")) %>%
#   mutate(categories = case_when(
#     categories == "null" ~ "Other",
#     categories == "" ~ "Other",
#     str_detect(categories, "^#+$") ~ "Other",
#     TRUE ~ categories
#   )) %>%
#   # Split by comma
#   separate_rows(categories, sep = ",") %>%
#   # Clean up each value
#   mutate(categories = str_trim(categories)) %>%
#   # Remove standalone "or" and "and" if they still exist
#   filter(!categories %in% c("or", "and", "")) %>%
#   # Get unique values
#   distinct(categories) %>%
#   # Sort alphabetically
#   arrange(categories)
# 
# 
# # Split all entries and get unique values
# unique_categories <- PITS_2023_2025_public %>%
#   mutate(categories = str_replace_all(`Infraction Categories`, "[,~]", ",")) %>%
#   # Split by comma
#   separate_rows(categories, sep = ",") %>%
#   # Clean up each value
#   mutate(categories = str_trim(categories)) %>%
#   # Remove "or" and "and" if they appear as standalone words after splitting
#   mutate(categories = str_replace(categories, "^(or|and)$", "")) %>%
#   # # Remove empty strings that might result from the replacements
#   # filter(categories != "") %>%
#   # filter(categories != "null") %>%
#   # # Filter out categories containing hash symbols
#   # filter(!str_detect(categories, "#")) %>%
#   mutate(categories = ifelse(categories == "or Illegal Conduct", "Illegal Conduct", categories)) %>%
#   # Get unique values
#   distinct(categories) %>%
#   # Sort alphabetically
#   arrange(categories)
# 
# print(unique_categories)
# print(paste("Number of unique categories:", nrow(unique_categories)))

``` 

# apply the other parsing category fct
```{r}
# PITS_empty_categories2 <- PITS_empty_categories %>%
#   mutate(parsed_categories = lapply(category_source, parse_categories)) %>%
#   unnest(parsed_categories)
```

# run parsed_categories for empty categories
```{r}
PITS_empty_categories 
```


# merge datasets
```{r}
# merge datasets
PITS_categories <- rbind(PITS_empty, PITS_categories)
```

```{r}
# count the pits categories

```


```{r}
  # Now pivot wider with each category becoming a column (1 = present)
PITS_categories_wide <- PITS_categories %>%
  # Create value = 1 for each category present
  mutate(value = 1) %>%
  # Pivot to wide format
  pivot_wider(
    id_cols = row_id,
    names_from = categories,
    values_from = value,
    values_fill = 0  # Fill missing with 0
  )

# Join back to original data frame
PITS_result <- PITS_2023_2025_public %>%
  mutate(row_id = row_number()) %>%
  left_join(PITS_categories_wide, by = "row_id") %>%
  select(-row_id)  # Remove the temporary row_id

# View the result
head(PITS_result)
```


#finer grained categories with infraction column
```{r}

# table(PITS_categories$categories)
# 
# # Now pivot wider with each category becoming a column (1 = present)
# PITS_categories_wide <- PITS_categories %>%
#   # Create value = 1 for each category present
#   mutate(value = 1) %>%
#   distinct(row_id, categories, .keep_all = TRUE) %>%
#   # Pivot to wide format
#   pivot_wider(
#     id_cols = row_id,
#     names_from = categories,
#     values_from = value,
#     values_fill = 0  # Fill missing with 0
#   )
# 
# # Join back to original data frame
# PITS_result <- PITS_2023_2025_public %>%
#   mutate(row_id = row_number()) %>%
#   left_join(PITS_categories_wide, by = "row_id") %>%
#   select(-row_id)  # Remove the temporary row_id
# 
# # View the result
# head(PITS_result)
```


```{r}

```


```{r}

```

```{r}


```

## Write csv

```{r}
write.csv(PITS_2023_2025_public, "pits2023-2025-public.csv")
```